{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6a7872-5d8d-4c26-a798-abaded55460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import time\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e7c7c2-5e86-4db1-bbc9-7a35c03dc615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([ 1.,  6.,  2., 13., 10., 13., 10.,  3.,  5.,  2.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.]), [7, 0, 0], [3, 0, 0], False], [tensor([ 1., 13.,  3., 13., 10.,  6.,  5.,  2., 13., 10., 13., 10.,  6.,  5.,\n",
      "         2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.]), [11, 2, 0], [10, 3, 0], False]]\n",
      "[[tensor([ 1., 12., 10.,  9.,  7.,  4., 11., 11.,  3.,  4.,  6., 12.,  3., 12.,\n",
      "         8.,  2.,  6.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.]), [12, 8, 0], [3, 3, 0], True], [tensor([ 1.,  6.,  2.,  8.,  5.,  6., 13., 11., 13.,  3.,  6., 11.,  2.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.]), [9, 0, 0], [3, 0, 0], True]]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(4)\n",
    "vocab_len = 10 #词表的大小\n",
    "max_len = 20 #每句话的最大长度\n",
    "batch_size = 4 #每个批次句子的数量\n",
    "max_pred = 3 # 最多mask的token数量\n",
    "\n",
    "sentence_len = torch.randint(1, max_len, (batch_size,)) #根据最大长度生成每个句子的具体长度\n",
    "sentence = [torch.randint(4, vocab_len + 4, (L,)) for L in sentence_len] #根据每个句子具体长度生成token\n",
    "\n",
    "#PAD : 0, CLS : 1, SEQ : 2, MASK : 3\n",
    "negative = []#二分类正样本\n",
    "positive = []#二分类负样本\n",
    "visit_seq = [] #保证不选重\n",
    "while len(positive) != batch_size / 2 or len(negative) != batch_size / 2:\n",
    "    a_index, b_index = randrange(len(sentence)), randrange(len(sentence))\n",
    "    while (a_index, b_index) in visit_seq:#保证不选重\n",
    "         a_index, b_index = randrange(len(sentence)), randrange(len(sentence))\n",
    "    visit_seq.append((a_index, b_index))\n",
    "\n",
    "    a, b = sentence[a_index], sentence[b_index]\n",
    "    input_ids = torch.cat([torch.ones(1,), a, torch.ones(1,).fill_(2), b, torch.ones(1,).fill_(2)])#预测任务token\n",
    "    segment_ids = torch.cat([torch.zeros(2 + len(a)), torch.ones(1 + len(b))])#二分类token\n",
    "\n",
    "    n_pred = min(max_pred, max(1, int(len(input_ids) * 0.15)))#该句子中需要预测的token数量\n",
    "    can_masked_pos = [i for i, token in enumerate(input_ids) if token != 1 and token != 2] \n",
    "    pos_masked = sample(can_masked_pos, n_pred)#随机选masked的位置\n",
    "    # print(pos_masked)\n",
    "\n",
    "    masked_tokens = []\n",
    "    masked_pos = []\n",
    "    for pos in pos_masked:\n",
    "        masked_pos.append(pos)\n",
    "        p = random()\n",
    "        if p < 0.8:#以0.8的概率masked掉\n",
    "            input_ids[pos] = 3\n",
    "            masked_tokens.append(3)\n",
    "        elif p > 0.9:#以0.1的概率随机选一个token填上\n",
    "            index = randint(4, vocab_len + 4)\n",
    "            input_ids[pos] = index\n",
    "            masked_tokens.append(index)\n",
    "            #以0.1的概率不变\n",
    "    if max_pred > n_pred: #如果能够masked掉的token数量不够，那么填上pad\n",
    "        n_pad = max_pred - n_pred\n",
    "        masked_tokens.extend([0] * n_pad)\n",
    "        masked_pos.extend([0] * n_pad)\n",
    "    npad = max_len * 2 - len(input_ids)\n",
    "    input_ids = torch.cat([input_ids, torch.zeros(npad,)]) #给这两个token进行padding\n",
    "    segment_ids = torch.cat([segment_ids, torch.zeros(npad, )])\n",
    "    if a_index + 1 == b_index and len(positive) < batch_size / 2:#采样，最后一个bool标记是二分类任务的标记\n",
    "        positive.append([input_ids, segment_ids, masked_pos, masked_tokens, True])\n",
    "    elif a_index + 1 != b_index and len(negative) < batch_size / 2:\n",
    "        negative.append([input_ids, segment_ids, masked_pos, masked_tokens, False])\n",
    "            \n",
    "    \n",
    "print(negative)\n",
    "print(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ce31d7f-0b80-4b67-aedb-78df6400277a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 13]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 3 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPlearning",
   "language": "python",
   "name": "nlplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
